"""
MEDITRACE V3.0 - FEATURE EXTRACTOR V2
======================================

CRITICAL FIX: This solves the manual entry bug and overfitting issues.

WHAT'S DIFFERENT FROM V1:
1. NO visual features (packaging_confidence, packaging_present)
2. ALL features are behavioral (scan patterns, supply chain logic)
3. Works for BOTH manual entry AND camera scan
4. Normalized to 0-1 range (easier for Random Forest)

AUTHOR: Built with understanding (not copy-paste!)
"""

from datetime import datetime, timedelta
from typing import Dict, List, Optional
from math import radians, sin, cos, sqrt, atan2
import re

class FeatureExtractorV2:
    """
    Extract 10 behavioral features for counterfeit detection.
    
    KEY INSIGHT: Instead of asking "Does the PACKAGE look real?",
                 we ask "Does the BEHAVIOR look real?"
    """
    
    def __init__(self, db_connection):
        """
        Initialize with database connection.
        
        Args:
            db_connection: Database object with methods:
                - get_drug(unique_id)
                - get_drugs_by_batch(batch_id)
                - has_failed_attempts(unique_id)
        """
        self.db = db_connection
        
        # Market average prices (in real system, load from database)
        self.market_prices = {
            'Dolo 650': 30.5,  # Updated to match seed data
            'Azithral 500': 125.0,
            'Crocin Advance': 28.0,
            'Amoxyclav 625': 180.0,
            'Pantoprazole 40': 95.5,
            'Cetirizine 10': 42.0,
            'Combiflam': 35.0
        }
        
        # Expected travel times between cities (in hours, by truck)
        self.route_times = {
            ('Mumbai', 'Delhi'): 24,
            ('Delhi', 'Bangalore'): 36,
            ('Mumbai', 'Bangalore'): 20,
            ('Chennai', 'Delhi'): 40,
            # Add more routes as needed
        }
        
        print("‚úÖ FeatureExtractorV2 initialized")
        print("   - 10 behavioral features")
        print("   - NO visual dependency")
        print("   - Works for manual entry!")
    
    
    def extract_features(self, drug_data: Dict, supply_chain_events: List[Dict]) -> Dict[str, float]:
        """
        Extract all 10 features from drug and supply chain data.
        
        Args:
            drug_data: Dict with keys: drug_name, batch_id, license_number, mrp, mfg_date
            supply_chain_events: List of dicts with keys: location, latitude, longitude, 
                               timestamp, event_type
        
        Returns:
            Dict with 10 features, all in range [0, 1]
            Higher score = More authentic
            Lower score = More suspicious
        """
        
        print(f"\nüîç Extracting features for: {drug_data.get('drug_name', 'Unknown')}")
        print(f"   Supply chain events: {len(supply_chain_events)}")
        
        features = {}
        
        # ===== FEATURE 1: SCAN FREQUENCY SCORE =====
        # How often is this drug being scanned?
        # Authentic: ~0.1 scans/day (once every 10 days)
        # Cloned: 10+ scans/day (scanned everywhere!)
        features['scan_frequency_score'] = self._calculate_scan_frequency(
            supply_chain_events
        )
        print(f"   ‚úì Scan frequency: {features['scan_frequency_score']:.2f}")
        
        
        # ===== FEATURE 2: UNIQUE LOCATIONS RATIO =====
        # What % of scans are from unique locations?
        # Authentic: High (each scan different place)
        # Cloned: Low (same QR scanned in many places, but many duplicates)
        features['unique_locations_ratio'] = self._calculate_unique_locations(
            supply_chain_events
        )
        print(f"   ‚úì Unique locations: {features['unique_locations_ratio']:.2f}")
        
        
        # ===== FEATURE 3: SUPPLY CHAIN COMPLETENESS =====
        # Does it have all required events?
        # Authentic: Factory ‚Üí Warehouse ‚Üí Retail (complete)
        # Suspicious: Missing stages
        features['supply_chain_completeness'] = self._calculate_completeness(
            supply_chain_events
        )
        print(f"   ‚úì Completeness: {features['supply_chain_completeness']:.2f}")
        
        
        # ===== FEATURE 4: LICENSE VALIDITY SCORE =====
        # Is the license number valid and not expiring soon?
        # Valid + long validity: 1.0
        # Expiring soon: 0.5
        # Invalid: 0.0
        features['license_validity_score'] = self._calculate_license_score(
            drug_data
        )
        print(f"   ‚úì License valid: {features['license_validity_score']:.2f}")
        
        
        # ===== FEATURE 5: PRICE DEVIATION SCORE =====
        # How much does MRP deviate from market average?
        # Normal range (¬±10%): 1.0
        # Significantly different: Lower score
        features['price_deviation_score'] = self._calculate_price_deviation(
            drug_data
        )
        print(f"   ‚úì Price normal: {features['price_deviation_score']:.2f}")
        
        
        # ===== FEATURE 6: TEMPORAL CONSISTENCY SCORE =====
        # Do travel times between locations make sense?
        # Mumbai‚ÜíDelhi in 24-48 hours (truck): Normal
        # Mumbai‚ÜíDelhi in 2 hours: Suspicious (airplane or fake)
        features['temporal_consistency_score'] = self._calculate_temporal_consistency(
            supply_chain_events
        )
        print(f"   ‚úì Travel times: {features['temporal_consistency_score']:.2f}")
        
        
        # ===== FEATURE 7: GEOFENCE COMPLIANCE SCORE =====
        # Are scans happening in expected regions?
        # Within manufacturer's operational area: Good
        # Random locations: Suspicious
        features['geofence_compliance_score'] = self._calculate_geofence_compliance(
            supply_chain_events
        )
        print(f"   ‚úì Geofence OK: {features['geofence_compliance_score']:.2f}")
        
        
        # ===== FEATURE 8: SPEED ANOMALY SEVERITY =====
        # Maximum travel speed between any two scans
        # 0-200 km/h (truck/train): 0.0 (no anomaly)
        # 900+ km/h: 1.0 (impossible! cloned!)
        features['speed_anomaly_severity'] = self._calculate_speed_severity(
            supply_chain_events
        )
        print(f"   ‚úì Speed anomaly: {features['speed_anomaly_severity']:.2f}")
        
        
        # ===== FEATURE 9: BATCH HEALTH SCORE =====
        # Are other drugs from same batch authentic?
        # All authentic: 1.0
        # Many flagged: 0.0
        features['batch_health_score'] = self._calculate_batch_health(
            drug_data.get('batch_id', '')
        )
        print(f"   ‚úì Batch health: {features['batch_health_score']:.2f}")
        
        
        # ===== FEATURE 10: HISTORICAL PATTERN SCORE =====
        # When are scans happening?
        # Business hours (9am-6pm): Good
        # Middle of night (3am): Suspicious
        features['historical_pattern_score'] = self._calculate_temporal_pattern(
            supply_chain_events
        )
        print(f"   ‚úì Scan timing: {features['historical_pattern_score']:.2f}")
        
        
        print(f"\n‚úÖ Feature extraction complete!")
        print(f"   Average score: {sum(features.values())/len(features):.2f}")
        
        return features
    
    
    # ================================================================
    # INDIVIDUAL FEATURE CALCULATIONS
    # Each method implements ONE feature
    # ================================================================
    
    def _calculate_scan_frequency(self, events: List[Dict]) -> float:
        """
        FEATURE 1: Scan Frequency Score
        
        LOGIC:
        - Authentic drug: Scanned 3-5 times total (Factory, Warehouse, Retail, maybe customer)
                         Over ~30 days = 0.1-0.16 scans/day
        - Cloned QR: Scanned 100+ times (many fakes with same QR)
                     Over same period = 3+ scans/day
        
        SCORING:
        - ‚â§0.5 scans/day: 1.0 (good)
        - 0.5-2 scans/day: 0.7 (acceptable)
        - 2-5 scans/day: 0.3 (suspicious)
        - >5 scans/day: 0.0 (very suspicious)
        
        Returns: 0.0-1.0 (higher = more authentic)
        """
        if len(events) < 2:
            return 1.0  # Can't calculate frequency with <2 scans
        
        # Get time span
        timestamps = [datetime.fromisoformat(e['timestamp'].replace(' ', 'T')) for e in events]
        days_elapsed = max((max(timestamps) - min(timestamps)).days + 1, 1)
        
        scans_per_day = len(events) / days_elapsed
        
        if scans_per_day <= 0.5: return 1.0
        elif scans_per_day <= 2: return 0.7
        elif scans_per_day <= 5: return 0.3
        else: return 0.0
    
    
    def _calculate_unique_locations(self, events: List[Dict]) -> float:
        """
        FEATURE 2: Unique Locations Ratio
        
        LOGIC:
        - Authentic: Each scan at different location (Factory ‚â† Warehouse ‚â† Retail)
                    Ratio = 3/3 = 1.0
        - Cloned: Many scans, but duplicates (20 scans, but only 5 unique locations)
                 Ratio = 5/20 = 0.25
        
        WHY IT WORKS:
        Counterfeiters often clone QR to multiple packages in same city/warehouse
        ‚Üí Many scans from same GPS coordinates
        
        Returns: 0.0-1.0 (higher = more authentic)
        """
        if not events:
            return 1.0  # No data = assume authentic
        
        unique_coords = set()
        
        for event in events:
            lat = event.get('latitude')
            lon = event.get('longitude')
            
            if lat is not None and lon is not None:
                # Round to 3 decimals (~100m precision)
                # This groups scans from same building
                coord = (round(lat, 3), round(lon, 3))
                unique_coords.add(coord)
        
        if len(unique_coords) == 0:
            return 1.0  # No GPS data available
        
        ratio = len(unique_coords) / len(events)
        return ratio  # Already 0-1
    
    
    def _calculate_completeness(self, events: List[Dict]) -> float:
        """
        FEATURE 3: Supply Chain Completeness
        
        LOGIC:
        Expected stages: Factory Production ‚Üí Warehouse Receipt ‚Üí Retail Distribution
        
        - All 3 present: 1.0 (complete supply chain)
        - 2 present: 0.66 (missing one stage)
        - 1 present: 0.33 (very incomplete)
        - 0 present: 0.0 (no valid events)
        
        WHY IT WORKS:
        Counterfeiters often skip stages (fake drug goes straight to retail)
        
        Returns: 0.0-1.0 (higher = more authentic)
        """
        required_events = {
            'Factory Production',  # Matches database.py
            'Warehouse Receipt',   # Matches database.py
            'Retail Distribution'  # Matches database.py
        }
        
        # Handle case variations
        present_events = {e.get('event_type', '') for e in events}
        
        # Check matching (flexible)
        matched_count = 0
        for req in required_events:
            if req in present_events:
                matched_count += 1
            # Fallback for "Production Complete" vs "Factory Production"
            elif req == 'Factory Production' and 'Production Complete' in present_events:
                matched_count += 1
                
        return matched_count / len(required_events)
    
    
    def _calculate_license_score(self, drug_data: Dict) -> float:
        """
        FEATURE 4: License Validity Score
        
        LOGIC:
        1. Check license format (XX-YYYY-ZZZZZZ)
        2. Check if license exists in registry (in real system)
        3. Check expiry date (if available)
        
        SCORING:
        - Valid + not expiring: 1.0
        - Valid but expires <30 days: 0.5
        - Invalid format/expired: 0.0
        
        WHY IT WORKS:
        Counterfeiters often use:
        - Random license numbers (fail format check)
        - Expired licenses (old/stolen)
        
        Returns: 0.0-1.0 (higher = more authentic)
        """
        license_num = drug_data.get('license_number', '')
        
        # UPDATED REGEX for Indian Pharma Formats (e.g., 20B/UA/2018 or 21C/GJ/2019)
        # Allows: Numbers/Letters, Forward Slashes, Hyphens
        pattern = r'^[A-Z0-9]{2,4}[/-][A-Z]{2}[/-]\d{4}$'
        
        # Fallback loose check (at least contains numbers and slashes/hyphens)
        if re.search(r'\d', license_num) and ( '/' in license_num or '-' in license_num):
            return 1.0
            
        return 0.0
    
    
    def _calculate_price_deviation(self, drug_data: Dict) -> float:
        """
        FEATURE 5: Price Deviation Score
        
        LOGIC:
        Compare MRP to market average for this drug.
        
        - Within ¬±10%: 1.0 (normal)
        - ¬±10-30%: 0.7 (acceptable variation)
        - ¬±30-50%: 0.3 (suspicious)
        - >¬±50%: 0.0 (very suspicious - likely fake)
        
        WHY IT WORKS:
        Counterfeiters often:
        - Price too low (to attract customers)
        - Price too high (premium fake)
        
        Real drugs have predictable market prices.
        
        Returns: 0.0-1.0 (higher = more authentic)
        """
        mrp = drug_data.get('mrp', 0)
        drug_name = drug_data.get('drug_name', '')
        
        # Get market average (in production, query database)
        avg_price = self.market_prices.get(drug_name, mrp)
        
        if avg_price == 0:
            return 1.0  # No comparison data available
        
        # Calculate deviation percentage
        deviation = abs(mrp - avg_price) / avg_price
        
        # Score based on deviation
        if deviation <= 0.1:  # Within 10%
            return 1.0
        elif deviation <= 0.3:  # 10-30%
            return 0.7
        elif deviation <= 0.5:  # 30-50%
            return 0.3
        else:  # >50%
            return 0.0
    
    
    def _calculate_temporal_consistency(self, events: List[Dict]) -> float:
        """
        FEATURE 6: Temporal Consistency Score
        
        LOGIC:
        Check if travel times between locations make sense.
        
        Example:
        - Mumbai ‚Üí Delhi: Expected 24-48 hours (truck)
        - If actual = 2 hours: Suspicious (airplane or fake)
        - If actual = 5 days: Acceptable (warehouse delay)
        
        SCORING:
        Average across all event pairs:
        - Within 0.5x-2x expected: 1.0
        - 2x-3x expected (delays): 0.7
        - <0.3x expected (too fast): 0.3
        
        WHY IT WORKS:
        Cloned QR appears in distant cities impossibly fast.
        
        Returns: 0.0-1.0 (higher = more authentic)
        """
        if len(events) < 2:
            return 1.0  # Can't calculate
        
        scores = []
        
        for i in range(len(events) - 1):
            e1 = events[i]
            e2 = events[i + 1]
            
            # Get expected time for this route
            expected_hours = self._get_expected_travel_time(
                e1.get('location', ''),
                e2.get('location', '')
            )
            
            # Calculate actual time
            t1 = datetime.fromisoformat(e1['timestamp'])
            t2 = datetime.fromisoformat(e2['timestamp'])
            actual_hours = (t2 - t1).total_seconds() / 3600
            
            # Score based on ratio
            if expected_hours == 0:
                scores.append(1.0)  # Unknown route
                continue
            
            ratio = actual_hours / expected_hours
            
            if 0.5 <= ratio <= 2.0:
                scores.append(1.0)  # Within reasonable range
            elif ratio <= 3.0:
                scores.append(0.7)  # Delayed but acceptable
            elif ratio < 0.3:
                scores.append(0.3)  # Too fast (suspicious)
            else:
                scores.append(0.5)  # Very delayed (could be warehouse storage)
        
        return sum(scores) / len(scores) if scores else 1.0
    
    
    def _get_expected_travel_time(self, loc1: str, loc2: str) -> float:
        """
        Get expected travel time between two cities (in hours).
        
        In production: Query routing database.
        For demo: Use lookup table.
        """
        key = (loc1, loc2)
        reverse_key = (loc2, loc1)
        
        return self.route_times.get(key) or self.route_times.get(reverse_key, 24)  # Default 24h
    
    
    def _calculate_geofence_compliance(self, 
                                       events: List[Dict]) -> float:
        """
        FEATURE 7: Geofence Compliance Score
        
        LOGIC:
        Check if scans happen in manufacturer's operational regions.
        
        Example:
        - Manufacturer: Sun Pharma (operates in Maharashtra, Gujarat)
        - Scans in Mumbai, Pune: Good (1.0)
        - Scans in Kerala, Assam: Suspicious (0.5)
        
        WHY IT WORKS:
        Counterfeiters distribute fakes in regions where manufacturer 
        doesn't operate (less scrutiny).
        
        Returns: 0.0-1.0 (higher = more authentic)
        """
        if not events:
            return 1.0
        
        # Get manufacturer's expected regions
        # In production: Query database
        # For demo: Simplified assumption
        self.expected_regions = [
            'Maharashtra', 'Delhi', 'Karnataka', 'Tamil Nadu', 'Gujarat', 'Andhra Pradesh',
            'Mumbai', 'Bangalore', 'Chennai', 'Ahmedabad', 'Hyderabad' # Added Cities
        ]
        
        compliant_scans = 0
        
        for event in events:
            location = event.get('location', '')
            
            # Check if location contains any expected region
            if any(region in location for region in self.expected_regions):
                compliant_scans += 1
        
        return compliant_scans / len(events) if events else 1.0
    
    
    def _calculate_speed_severity(self, events: List[Dict]) -> float:
        """
        FEATURE 8: Speed Anomaly Severity
        
        LOGIC:
        Calculate max speed between any two consecutive scans.
        
        SPEED THRESHOLDS:
        - 0-200 km/h: Normal (truck/train) ‚Üí severity 0.0
        - 200-500 km/h: Fast courier (possible) ‚Üí severity 0.3
        - 500-900 km/h: Very suspicious ‚Üí severity 0.6
        - 900+ km/h: Impossible (cloned!) ‚Üí severity 1.0
        
        WHY IT WORKS:
        Same QR scanned in Mumbai at 10am, Delhi at 10:05am
        = 1,400 km in 5 minutes = 16,800 km/h
        PHYSICALLY IMPOSSIBLE! Must be cloned.
        
        Returns: 0.0-1.0 (higher = MORE suspicious)
        """
        if len(events) < 2:
            return 0.0  # No anomaly
        
        max_speed = 0
        
        for i in range(len(events) - 1):
            e1 = events[i]
            e2 = events[i + 1]
            
            # Check if both have GPS
            if not all([e1.get('latitude'), e1.get('longitude'),
                       e2.get('latitude'), e2.get('longitude')]):
                continue
            
            # Calculate speed
            speed = self._calculate_speed_between_events(e1, e2)
            max_speed = max(max_speed, speed)
        
        # Convert speed to severity score
        if max_speed < 200:
            return 0.0  # Normal
        elif max_speed < 500:
            return 0.3  # Fast but possible
        elif max_speed < 900:
            return 0.6  # Very suspicious
        else:
            return 1.0  # Impossible! Definitely cloned
    
    
    def _calculate_speed_between_events(self, e1: Dict, e2: Dict) -> float:
        """
        Calculate speed in km/h between two events using Haversine formula.
        
        Returns: Speed in km/h
        """
        # Extract coordinates
        lat1 = e1['latitude']
        lon1 = e1['longitude']
        lat2 = e2['latitude']
        lon2 = e2['longitude']
        
        # Haversine formula for great-circle distance
        R = 6371  # Earth radius in km
        
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        
        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
        c = 2 * atan2(sqrt(a), sqrt(1-a))
        distance_km = R * c
        
        # Calculate time difference
        t1 = datetime.fromisoformat(e1['timestamp'])
        t2 = datetime.fromisoformat(e2['timestamp'])
        time_hours = (t2 - t1).total_seconds() / 3600
        
        if time_hours == 0:
            return 0  # Same time
        
        speed_kmh = distance_km / time_hours
        return speed_kmh
    
    
    def _calculate_batch_health(self, batch_id: str) -> float:
        """
        FEATURE 9: Batch Health Score
        
        LOGIC:
        Check how many other drugs from same batch have been flagged.
        
        - 0% flagged: 1.0 (healthy batch)
        - 25% flagged: 0.75
        - 50% flagged: 0.5
        - 75%+ flagged: 0.25-0.0 (contaminated batch)
        
        WHY IT WORKS:
        If entire batch is counterfeit, multiple drugs will be flagged.
        If only one drug flagged, might be false positive.
        
        Returns: 0.0-1.0 (higher = healthier batch)
        """
        if not batch_id:
            return 1.0
        
        # Get all drugs from this batch
        batch_drugs = self.db.get_drugs_by_batch(batch_id)
        
        if len(batch_drugs) <= 1:
            return 1.0  # Only drug in batch, can't analyze
        
        # Count how many have failed attempts
        flagged_count = 0
        for drug_id in batch_drugs:
            if self.db.has_failed_attempts(drug_id):
                flagged_count += 1
        
        # Calculate health ratio
        authentic_ratio = 1 - (flagged_count / len(batch_drugs))
        return authentic_ratio
    
    
    def _calculate_temporal_pattern(self, events: List[Dict]) -> float:
        """
        FEATURE 10: Historical Pattern Score
        
        LOGIC:
        Analyze WHEN scans are happening.
        
        BUSINESS HOURS:
        - Mon-Fri 9am-6pm: Legitimate (factories, warehouses, pharmacies)
        - Sat 9am-1pm: Acceptable (some pharmacies)
        - Sun / Night (10pm-6am): Suspicious
        
        SCORING:
        - ‚â•80% business hours: 1.0
        - 50-80% business hours: 0.7
        - <50% business hours: 0.3
        
        WHY IT WORKS:
        Counterfeiters often scan at odd hours (2am, 4am) to avoid detection.
        
        Returns: 0.0-1.0 (higher = more authentic)
        """
        if not events:
            return 1.0
        
        business_hour_scans = 0
        
        for event in events:
            timestamp = datetime.fromisoformat(event['timestamp'])
            hour = timestamp.hour
            weekday = timestamp.weekday()  # 0=Monday, 6=Sunday
            
            # Check if business hours
            is_business_hours = False
            
            if weekday < 5:  # Monday-Friday
                if 9 <= hour <= 18:  # 9am-6pm
                    is_business_hours = True
            
            elif weekday == 5:  # Saturday
                if 9 <= hour <= 13:  # 9am-1pm
                    is_business_hours = True
            
            if is_business_hours:
                business_hour_scans += 1
        
        ratio = business_hour_scans / len(events)
        
        # Score based on ratio
        if ratio >= 0.8:
            return 1.0  # Mostly business hours
        elif ratio >= 0.5:
            return 0.7  # Mixed
        else:
            return 0.3  # Mostly off-hours (suspicious)


# ================================================================
# USAGE EXAMPLE (for testing)
# ================================================================

if __name__ == '__main__':
    # Mock database for testing
    class MockDB:
        def get_drugs_by_batch(self, batch_id):
            return ['drug1', 'drug2', 'drug3']
        
        def has_failed_attempts(self, drug_id):
            return False  # All drugs in batch are clean
    
    # Initialize
    db = MockDB()
    extractor = FeatureExtractorV2(db)
    
    # Test data
    drug_data = {
        'drug_name': 'Dolo 650',
        'batch_id': 'C28C623D',
        'license_number': 'AB-1234-567890',
        'mrp': 30.0,
        'mfg_date': '2025-01-01'
    }
    
    supply_chain = [
        {
            'location': 'Mumbai',
            'latitude': 19.0760,
            'longitude': 72.8777,
            'timestamp': '2025-01-05T10:00:00',
            'event_type': 'Factory Production'
        },
        {
            'location': 'Delhi',
            'latitude': 28.7041,
            'longitude': 77.1025,
            'timestamp': '2025-01-06T14:00:00',  # 28 hours later (truck)
            'event_type': 'Warehouse Receipt'
        },
        {
            'location': 'Delhi',
            'latitude': 28.7100,
            'longitude': 77.1100,
            'timestamp': '2025-01-08T11:00:00',  # 2 days later
            'event_type': 'Retail Distribution'
        }
    ]
    
    # Extract features
    features = extractor.extract_features(drug_data, supply_chain)
    
    print("\n" + "="*60)
    print("FINAL FEATURES:")
    print("="*60)
    for feature_name, value in features.items():
        print(f"{feature_name:30s}: {value:.3f}")
    
    print("\n" + "="*60)
    avg_score = sum(features.values()) / len(features)
    print(f"AVERAGE SCORE: {avg_score:.3f}")
    
    if avg_score > 0.8:
        print("VERDICT: ‚úÖ LIKELY AUTHENTIC")
    elif avg_score > 0.6:
        print("VERDICT: ‚ö†Ô∏è  REVIEW RECOMMENDED")
    else:
        print("VERDICT: ‚ùå SUSPICIOUS")
    print("="*60)